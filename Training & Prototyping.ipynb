{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import lasagne\n",
    "import loading\n",
    "\n",
    "# todo: get rid of relative imports, except autoload_data\n",
    "from autoload_data import *    # pulls in directory names and several views and functions on data\n",
    "from training import *\n",
    "from network import *\n",
    "from experiments import *\n",
    "import architectures as arches\n",
    "import autoencoder as ae\n",
    "\n",
    "# aliases\n",
    "L = lasagne.layers\n",
    "T = theano.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subnet_conv',\n",
       " 'subnet_dense',\n",
       " 'subnet_conv',\n",
       " 'subnet_dense',\n",
       " 'subnet_conv',\n",
       " 'subnet_dense',\n",
       " 'subnet_conv',\n",
       " 'subnet_dense',\n",
       " 'subnet_conv',\n",
       " 'subnet_dense',\n",
       " 'subnet_conv',\n",
       " 'subnet_dense',\n",
       " 'subnet_conv',\n",
       " 'subnet_dense',\n",
       " 'subnet_conv',\n",
       " 'subnet_dense',\n",
       " 'subnet_conv',\n",
       " 'subnet_dense',\n",
       " <theano.tensor.elemwise.Elemwise at 0x1a07b52518>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ivar = T.tensor4('inputs')\n",
    "net = arches.multiconvX_ws(ivar)\n",
    "layers = L.get_all_layers(net)\n",
    "named = [layer for layer in layers if layer.name is not None]\n",
    "conv = [layer for layer in named if 'conv' in layer.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<lasagne.layers.input.InputLayer at 0x1c096c54e0>,\n",
       " <lasagne.layers.conv.Conv2DLayer at 0x1c0a0c3390>,\n",
       " <lasagne.layers.special.ParametricRectifierLayer at 0x1c0a0c3ba8>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0c30f0>,\n",
       " <lasagne.layers.pool.FeaturePoolLayer at 0x1c0a0c3f98>,\n",
       " <lasagne.layers.dense.DenseLayer at 0x1c0a0c31d0>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0c3048>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c0a0b17b8>,\n",
       " <lasagne.layers.conv.Conv2DLayer at 0x1c0a0b1cf8>,\n",
       " <lasagne.layers.special.ParametricRectifierLayer at 0x1c0a0b1048>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0b13c8>,\n",
       " <lasagne.layers.pool.FeaturePoolLayer at 0x1c0a0b1128>,\n",
       " <lasagne.layers.dense.DenseLayer at 0x1c0a0b1358>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0b1e48>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c0a0b10f0>,\n",
       " <lasagne.layers.conv.Conv2DLayer at 0x1c0a0b1400>,\n",
       " <lasagne.layers.special.ParametricRectifierLayer at 0x1c0a0e0a58>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0e0048>,\n",
       " <lasagne.layers.pool.FeaturePoolLayer at 0x1c0a0e0240>,\n",
       " <lasagne.layers.dense.DenseLayer at 0x1c0a0e07f0>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0e0198>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c0a0e0828>,\n",
       " <lasagne.layers.conv.Conv2DLayer at 0x1c0a0e09e8>,\n",
       " <lasagne.layers.special.ParametricRectifierLayer at 0x1c0a0e0c50>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0e0438>,\n",
       " <lasagne.layers.pool.FeaturePoolLayer at 0x1c096c3f60>,\n",
       " <lasagne.layers.dense.DenseLayer at 0x1c096c3b38>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c096c3b70>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c096c3748>,\n",
       " <lasagne.layers.conv.Conv2DLayer at 0x1c096bde80>,\n",
       " <lasagne.layers.special.ParametricRectifierLayer at 0x1c096c3e10>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c096c3908>,\n",
       " <lasagne.layers.pool.FeaturePoolLayer at 0x1c096c3c18>,\n",
       " <lasagne.layers.dense.DenseLayer at 0x1c096c3da0>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c096c3cf8>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c096c39e8>,\n",
       " <lasagne.layers.conv.Conv2DLayer at 0x1c096c36d8>,\n",
       " <lasagne.layers.special.ParametricRectifierLayer at 0x1c096c34e0>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x102e10cf8>,\n",
       " <lasagne.layers.pool.FeaturePoolLayer at 0x102e103c8>,\n",
       " <lasagne.layers.dense.DenseLayer at 0x102e10dd8>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x102e10828>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x102e0efd0>,\n",
       " <lasagne.layers.conv.Conv2DLayer at 0x102e0e828>,\n",
       " <lasagne.layers.special.ParametricRectifierLayer at 0x1c0a0c8048>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0c84a8>,\n",
       " <lasagne.layers.pool.FeaturePoolLayer at 0x1c0a0c84e0>,\n",
       " <lasagne.layers.dense.DenseLayer at 0x1c0a0c8cf8>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0c8710>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c0a0c8be0>,\n",
       " <lasagne.layers.conv.Conv2DLayer at 0x1c0a0c80f0>,\n",
       " <lasagne.layers.special.ParametricRectifierLayer at 0x1c0a0c8550>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0c8fd0>,\n",
       " <lasagne.layers.pool.FeaturePoolLayer at 0x1c0a0c8b00>,\n",
       " <lasagne.layers.dense.DenseLayer at 0x1c0a0c8ba8>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c0a0c8390>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c096e0550>,\n",
       " <lasagne.layers.conv.Conv2DLayer at 0x1c096e04e0>,\n",
       " <lasagne.layers.special.ParametricRectifierLayer at 0x1c096e02e8>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c096e0358>,\n",
       " <lasagne.layers.pool.FeaturePoolLayer at 0x1c096e00f0>,\n",
       " <lasagne.layers.dense.DenseLayer at 0x1c096e0048>,\n",
       " <lasagne.layers.noise.DropoutLayer at 0x1c096e0e10>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c096e0470>,\n",
       " <customlayers.WeightedSumLayer at 0x1c0a0c3e10>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c096e0b00>,\n",
       " <lasagne.layers.special.NonlinearityLayer at 0x1c096e01d0>,\n",
       " <customlayers.make_FixLayer.<locals>.FixLayer at 0x1c096e0b38>,\n",
       " <customlayers.ReNormLayer at 0x1c096e0d30>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[layer for layer in layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theano.scan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theano.scan_module.reduce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder transfer learning\n",
    "\n",
    "Implementation note: the autoencoder object wraps a Theano graph. This graph can be divided into an *encoder*, which produces a vector of latent features, a *decoder*, which inverts the encoder to recover the original input, and a *classifier*, which produces a probability distribution over [0, 35].\n",
    "\n",
    "The encoder is shared between the encoder+decoder (`Autoencoder.autoencoder`) and the encoder+classifier (`Autoencoder.network`), so once the enc+dec is trained (unsupervised), enc can have its weights fixed and enc+cla can be trained (supervised).\n",
    "\n",
    "You could modify this (typical) scheme; just be aware that the encoder is shared by `Autoencoder.autoencoder` and `Autoencoder.network`. See `autoencoder.py` for example architecture, `network.py` for `Autoencoder` implementation, and `training.py` for `AutoencoderTrainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(ae.autoencoder)                          # initialize autoencoder obj\n",
    "ae_trainer = AutoencoderTrainer(stopthresh=1, print_interval=1)    # initialize trainer\n",
    "\n",
    "ae_start_params = L.get_all_param_values(autoencoder.autoencoder)  # cache starting parameters(move to network obj)\n",
    "ae_trainer.train_autoencoder(autoencoder, np.concatenate(data[2])) # train autoencoder\n",
    "\n",
    "ae_end_params = L.get_all_param_values(autoencoder.autoencoder)    # cache trained params\n",
    "autoencoder.freeze_params(exclude=list(range(-7, 0)))              # set all params untrainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ae_trainer.stopthresh = 5 \n",
    "ae_trainer.print_interval = 20\n",
    "net_list = ae_trainer.train_all(autoencoder, data=hvhdata, seed=984227)    # train classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param count: 8849\n",
      "{'kwargs': {'subnet_specs': [[4, [1, 4]], [4, [4, 1]], [4, [4, 4]], [4, [4, 5]], [4, [4, 6]], [4, [4, 7]], [4, [4, 8]], [4, [1, 3]], [4, [3, 1]], [4, [3, 3]], [4, [1, 2]], [4, [2, 1]], [4, [2, 2]]]}, 'name': 'h4', 'type': 'multiconvX_ws'}\n",
      "\n",
      "Split Number 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-506d771bb10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'h4'\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;31m# list network handles from arch_specs.yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_tuned_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m                \u001b[0;31m# and awaaaay we go. see experiments.py for implementation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/nns-for-mnk/experiments.py\u001b[0m in \u001b[0;36mrun_tuned_experiment\u001b[0;34m(archnames)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# run tuned fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mrun_tuned_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhvhdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparamsdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparamsdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/nns-for-mnk/experiments.py\u001b[0m in \u001b[0;36mrun_tuned_fit\u001b[0;34m(architecture, data, hvhdata, paramsdir, tune, save, freeze)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefaultTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m# initialize trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mnet_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m985227\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# returns a list of networks trained on every split in data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# save params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/nns-for-mnk/training.py\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m(self, architecture, data, seed, save_params, augment_fn)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mnum_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0mnet_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/nns-for-mnk/training.py\u001b[0m in \u001b[0;36mrun_split\u001b[0;34m(self, architecture, data, split, augment_fn)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m)\u001b[0m                                                 \u001b[0;31m# compile network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# train network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                                       \u001b[0;31m# test network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/nns-for-mnk/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, network, training_data, validation_data)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mtrain_err_reg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mtrain_bats\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/tensor/nnet/abstract_conv.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out_)\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_flip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m             \u001b[0mkern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvdim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1788\u001b[0;31m         \u001b[0mconv_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_dilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_groups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1789\u001b[0m         conv_out = conv_out[(slice(None), slice(None)) +\n\u001b[1;32m   1790\u001b[0m                             tuple(slice(None, None, self.subsample[i])\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/theano/tensor/nnet/abstract_conv.py\u001b[0m in \u001b[0;36mconv\u001b[0;34m(self, img, kern, mode, dilation, num_groups)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                                 \u001b[0;31m# some cast generates a warning here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                                 out[b, g * output_channel_offset + n, ...] += _convolve2d(img[b, g * input_channel_offset + im0, ...],\n\u001b[0;32m-> 1691\u001b[0;31m                                                                                           dilated_kern[g * output_channel_offset + n,\n\u001b[0m\u001b[1;32m   1692\u001b[0m                                                                                           im0, ...], 1, val, bval, 0)\n\u001b[1;32m   1693\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "names = ['h4']    # list network handles from arch_specs.yaml\n",
    "run_tuned_experiment(names)                # and awaaaay we go. see experiments.py for implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Join.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_var = T.tensor4('inputs')\n",
    "net = arches.multiconvX_ws(input_var=input_var)\n",
    "ws = [p for p in L.get_all_params(net) if 'conv.W' in p.name]\n",
    "T.abs_(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk supplement training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names = ['g1', 'g2', 'g4', 'h1', 'h2', 'h4']\n",
    "run_bulk_experiment(names[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning\n",
    "\n",
    "**WIP**\n",
    "\n",
    "To Dos:\n",
    "- convert histories to reward signals\n",
    "- pass reward signals to networks\n",
    "- decide training scheme:\n",
    "    - network plays self\n",
    "    - network plays round robin with multiple architectures\n",
    "    - network plays RR with multiple architectures AND heuristic search models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.signal as sig\n",
    "filters = dict()\n",
    "filters['h'] = np.ones(4)[np.newaxis, :, np.newaxis]\n",
    "filters['v'] = np.ones(4)[np.newaxis, np.newaxis, :]\n",
    "filters['d'] = np.eye(4)[np.newaxis, :, :]\n",
    "filters['u'] = np.fliplr(np.eye(4))[np.newaxis, :, :]\n",
    "\n",
    "class GameState(object):\n",
    "    \"\"\"\n",
    "    Unless otherwise indicated, \"state\" should be a (1, 2, 4, 9) tensor,\n",
    "    with first channel representing OWN pieces (NOT black!)\n",
    "    \n",
    "    Would it better to have this as a stateless thing with class methods?\n",
    "    \"\"\"\n",
    "    \n",
    "    def init(self, state):\n",
    "        self.state = state\n",
    "        self.color = self.get_color()\n",
    "        self.terminal = self.terminal_check()\n",
    "    \n",
    "    def get_color(self):\n",
    "        if (self.state.sum() % 2) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    def update(self, move):\n",
    "        new_state = self.state.copy()\n",
    "        coords = np.unravel_index(move, (4, 9))\n",
    "        new_state[0, coords[0], coords[1]] = 1\n",
    "        return GameState(new_state[:, ::-1, :, :])    # invert channels!\n",
    "    \n",
    "    def terminal_check(self):\n",
    "        if state.sum() == 36:\n",
    "            return 'draw'\n",
    "        for dim, fil in filters.items():\n",
    "            filter_response = sig.convolve(self.state, fil, mode='valid')\n",
    "            if np.where(filter_response>=4)[0].size > 0:\n",
    "                return 'win'\n",
    "                \n",
    "        return False\n",
    "    \n",
    "    \n",
    "class RLTrainer(object):\n",
    "    \"\"\"\n",
    "    Unless otherwise indicated, \"gstate\" should be a GameState object\n",
    "    \"\"\"\n",
    "    def init(self, reward=1000, batchsize=100):\n",
    "        self.reward = reward\n",
    "        self.batchsize = batchsize\n",
    "    \n",
    "    def choose_move(self, network, gstate):\n",
    "        policy = network.output_fn(gstate.state)\n",
    "        return np.random.choice(36, p=policy)\n",
    "    \n",
    "    def play_game(self, network, gstate):\n",
    "        choices = []\n",
    "        states = [gstate.state]\n",
    "        \n",
    "        next_state = gstate\n",
    "        while not next_state.terminal:\n",
    "            action = self.choose_move(network, next_state)\n",
    "            choices.append(action)\n",
    "            next_state = next_state.update(action)\n",
    "            states.append(next_state.state)\n",
    "            \n",
    "        return choices, states\n",
    "    \n",
    "    def play_batch(self, network):\n",
    "        initial_state = np.zeros((1, 2, 4, 9))\n",
    "        choice_history = []\n",
    "        state_history = []\n",
    "        \n",
    "        for i in range(batchsize):\n",
    "            c, s = play_game(self, network, gstate)\n",
    "            choice_history.append(c)\n",
    "            state_history.append(s)\n",
    "            \n",
    "        return choice_history, state_history\n",
    "    \n",
    "    def compute_reward(self, choices):\n",
    "        if len(choices) == 36:\n",
    "            return 0\n",
    "        if (len(choices) % 2) == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    def convert_data(self, choice_history, state_history):\n",
    "        \"\"\"\n",
    "        To dos here:\n",
    "        \n",
    "        - compute outcome of each game (0 for draw, 1 for black win, -1 for white)\n",
    "        - tile those outcomes but alternating: \n",
    "            a game that has 10 moves ended in a win for white, so all EVEN locations\n",
    "            in vector should be +1 and all ODD locations should be -1\n",
    "            vice versa for a game with odd moves\n",
    "        - convert each set of choices and states in respective histories to \n",
    "            np arrays (n_games x whatev dims)\n",
    "            \n",
    "        - LATER: figure out how to pass array of outcomes to network update function!\n",
    "        \"\"\"\n",
    "        outcomes = [self.compute_reward(choices) for choices in choice_history]\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake news!\n",
    "\n",
    "Model recovery: train on fake data from another model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit best networks on fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_fake_experiment(['h4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject tuning\n",
    "\n",
    "Usually doesn't work (not enough data even for very simple classifier layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dafiname = os.path.join(datadir, '0 (with groups).csv')\n",
    "subject_data = [loading.default_loader(dafiname, subject=s) for s in range(40)]\n",
    "arch = archs[archname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print([len(s[0]) for s in subject_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    pafiname = '{} {} split agg fit exp 1-4.npz'.format(archname, i)\n",
    "    prenet = Network(arch)\n",
    "    prenet.load_params(os.path.join(paramsdir, pafiname))\n",
    "    params = L.get_all_param_values(prenet.net)\n",
    "    print('PREFIT {}\\n'.format(i))\n",
    "    \n",
    "    for s in range(40):\n",
    "        sdata = subject_data[s]\n",
    "        num_obs = len(sdata[0])\n",
    "        bs = num_obs//5\n",
    "        tuner = FineTuner(stopthresh=10, batchsize=bs)\n",
    "        print('SUBJECT {}\\n'.format(s))\n",
    "        \n",
    "        for j in range(5):\n",
    "            fname = '{} {} agg fit exp 1-4 {} subject {} tune fit exp 0'.format(archname, i, s, j)\n",
    "            net = tuner.train_all(architecture=arch, data=sdata, split=j, startparams=params, freeze=True)\n",
    "            net.save_params(os.path.join(paramsdir, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation\n",
    "\n",
    "doesn't need run more than once - move to script sometime, wouldja?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafilenames = ['0 (with groups)', '1 (with computer)', '2 (with computer)', '3 (with computer)', '4']\n",
    "datafilenames = [os.path.join(datadir, fname + '.csv') for fname in datafilenames]\n",
    "colnames = ['subject', 'color', 'bp', 'wp', 'zet', 'rt']\n",
    "\n",
    "e0 = pd.read_csv(datafilenames[0], names=colnames+['splitno'])\n",
    "e1 = pd.read_csv(datafilenames[1], names=colnames)\n",
    "e2 = pd.read_csv(datafilenames[2], names=colnames)\n",
    "e3 = pd.read_csv(datafilenames[3], names=colnames+['task', 'taskorder', 'session'])\n",
    "e4 = pd.read_csv(datafilenames[4], names=colnames+['timecondition'])\n",
    "Es = [e1, e2, e3, e4]\n",
    "for i, e in enumerate(Es[1:]):\n",
    "    e['subject'] = e['subject'] + Es[i-1].loc[Es[i-1]['subject']<1000, 'subject'].max()\n",
    "\n",
    "A = pd.concat([e[colnames] for e in [e1, e2, e3, e4]])\n",
    "\n",
    "groups = np.arange(len(A))%5 + 1\n",
    "np.random.seed(100001)\n",
    "np.random.shuffle(groups)\n",
    "A['group'] = groups\n",
    "\n",
    "A.to_csv(os.path.join(datadir, '1-4.csv'), encoding='ASCII', header=False, index=False)\n",
    "A.loc[A['subject']<1000, :].to_csv(\n",
    "    os.path.join(datadir, '1-4 (no computer).csv'), \n",
    "    encoding='ASCII', header=False, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this is for another training scheme, using preassigned groups in both hvh and other data\n",
    "bulkdata_df = pd.concat([data[0], hvhdata[0]])\n",
    "bulkdata_df.to_csv(os.path.join(datadir, 'bulk.csv'), index=False, header=False)\n",
    "bulkdata = loading.default_loader(os.path.join(datadir, 'bulk.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add groups to fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd_ = pd.read_csv(os.path.join(datadir, 'fake news.csv'), names=['subject', 'color', 'bp', 'wp', 'zet', 'rt'])\n",
    "\n",
    "groups = np.arange(len(fd_)) % 5 + 1\n",
    "np.random.shuffle(groups)\n",
    "fd_['group'] = groups\n",
    "fd_.to_csv(os.path.join(datadir, 'fake news (with groups).csv'), encoding='ASCII', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
