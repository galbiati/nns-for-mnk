{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import lasagne\n",
    "import loading\n",
    "from training import *\n",
    "from network import *\n",
    "from experiments import *\n",
    "import architectures as arches\n",
    "\n",
    "# aliases\n",
    "L = lasagne.layers\n",
    "T = theano.tensor\n",
    "\n",
    "# directories\n",
    "headdir = os.path.expanduser('~/Google Drive/Bas Zahy Gianni - Games')\n",
    "paramsdir_ = os.path.join(headdir, 'Analysis/0_hvh/Params/nnets/')\n",
    "datadir = os.path.join(headdir, 'Data/model input')\n",
    "resultsdir = os.path.join(headdir, 'Analysis/0_hvh/Loglik/nnets')\n",
    "\n",
    "# loading data\n",
    "data = loading.default_loader(os.path.join(datadir, '1-4 (no computer).csv'))\n",
    "hvhdata = loading.default_loader(os.path.join(datadir, '0 (with groups).csv'))\n",
    "Xs = np.concatenate(hvhdata[2])\n",
    "ys = np.concatenate(hvhdata[3])\n",
    "Ss = np.concatenate(hvhdata[4])\n",
    "\n",
    "# load network specs\n",
    "with open('arch_specs.yaml') as archfile:\n",
    "    arch_dict = yaml.load(archfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names = ['nopool_c7']\n",
    "run_tuned_experiment(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bulk supplement training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names = ['g1', 'g2', 'g4', 'h1', 'h2', 'h4']\n",
    "run_bulk_experiment(names[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.signal as sig\n",
    "filters = dict()\n",
    "filters['h'] = np.ones(4)[np.newaxis, :, np.newaxis]\n",
    "filters['v'] = np.ones(4)[np.newaxis, np.newaxis, :]\n",
    "filters['d'] = np.eye(4)[np.newaxis, :, :]\n",
    "filters['u'] = np.fliplr(np.eye(4))[np.newaxis, :, :]\n",
    "\n",
    "class GameState(object):\n",
    "    \"\"\"\n",
    "    Unless otherwise indicated, \"state\" should be a (1, 2, 4, 9) tensor,\n",
    "    with first channel representing OWN pieces (NOT black!)\n",
    "    \n",
    "    Would it better to have this as a stateless thing with class methods?\n",
    "    \"\"\"\n",
    "    \n",
    "    def init(self, state):\n",
    "        self.state = state\n",
    "        self.color = self.get_color()\n",
    "        self.terminal = self.terminal_check()\n",
    "    \n",
    "    def get_color(self):\n",
    "        if (self.state.sum() % 2) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    def update(self, move):\n",
    "        new_state = self.state.copy()\n",
    "        coords = np.unravel_index(move, (4, 9))\n",
    "        new_state[0, coords[0], coords[1]] = 1\n",
    "        return GameState(new_state[:, ::-1, :, :])    # invert channels!\n",
    "    \n",
    "    def terminal_check(self):\n",
    "        if state.sum() == 36:\n",
    "            return 'draw'\n",
    "        for dim, fil in filters.items():\n",
    "            filter_response = sig.convolve(self.state, fil, mode='valid')\n",
    "            if np.where(filter_response>=4)[0].size > 0:\n",
    "                return 'win'\n",
    "                \n",
    "        return False\n",
    "    \n",
    "    \n",
    "class RLTrainer(object):\n",
    "    \"\"\"\n",
    "    Unless otherwise indicated, \"gstate\" should be a GameState object\n",
    "    \"\"\"\n",
    "    def init(self, reward=1000, batchsize=100):\n",
    "        self.reward = reward\n",
    "        self.batchsize = batchsize\n",
    "    \n",
    "    def choose_move(self, network, gstate):\n",
    "        policy = network.output_fn(gstate.state)\n",
    "        return np.random.choice(36, p=policy)\n",
    "    \n",
    "    def play_game(self, network, gstate):\n",
    "        choices = []\n",
    "        states = [gstate.state]\n",
    "        \n",
    "        next_state = gstate\n",
    "        while not next_state.terminal:\n",
    "            action = self.choose_move(network, next_state)\n",
    "            choices.append(action)\n",
    "            next_state = next_state.update(action)\n",
    "            states.append(next_state.state)\n",
    "            \n",
    "        return choices, states\n",
    "    \n",
    "    def play_batch(self, network):\n",
    "        initial_state = np.zeros((1, 2, 4, 9))\n",
    "        choice_history = []\n",
    "        state_history = []\n",
    "        \n",
    "        for i in range(batchsize):\n",
    "            c, s = play_game(self, network, gstate)\n",
    "            choice_history.append(c)\n",
    "            state_history.append(s)\n",
    "            \n",
    "        return choice_history, state_history\n",
    "    \n",
    "    def compute_reward(self, choices):\n",
    "        if len(choices) == 36:\n",
    "            return 0\n",
    "        if (len(choices) % 2) == 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "    def convert_data(self, choice_history, state_history):\n",
    "        \"\"\"\n",
    "        To dos here:\n",
    "        \n",
    "        - compute outcome of each game (0 for draw, 1 for black win, -1 for white)\n",
    "        - tile those outcomes but alternating: \n",
    "            a game that has 10 moves ended in a win for white, so all EVEN locations\n",
    "            in vector should be +1 and all ODD locations should be -1\n",
    "            vice versa for a game with odd moves\n",
    "        - convert each set of choices and states in respective histories to \n",
    "            np arrays (n_games x whatev dims)\n",
    "            \n",
    "        - LATER: figure out how to pass array of outcomes to network update function!\n",
    "        \"\"\"\n",
    "        outcomes = [self.compute_reward(choices) for choices in choice_history]\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake news!\n",
    "\n",
    "Model recovery: train on fake data from another model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit best networks on fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_fake_experiment(['h4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names = ['tanh_h4']\n",
    "run_tuned_experiment(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject tuning\n",
    "\n",
    "Usually doesn't work (not enough data even for very simple classifier layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dafiname = os.path.join(datadir, '0 (with groups).csv')\n",
    "subject_data = [loading.default_loader(dafiname, subject=s) for s in range(40)]\n",
    "arch = archs[archname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print([len(s[0]) for s in subject_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    pafiname = '{} {} split agg fit exp 1-4.npz'.format(archname, i)\n",
    "    prenet = Network(arch)\n",
    "    prenet.load_params(os.path.join(paramsdir, pafiname))\n",
    "    params = L.get_all_param_values(prenet.net)\n",
    "    print('PREFIT {}\\n'.format(i))\n",
    "    \n",
    "    for s in range(40):\n",
    "        sdata = subject_data[s]\n",
    "        num_obs = len(sdata[0])\n",
    "        bs = num_obs//5\n",
    "        tuner = FineTuner(stopthresh=10, batchsize=bs)\n",
    "        print('SUBJECT {}\\n'.format(s))\n",
    "        \n",
    "        for j in range(5):\n",
    "            fname = '{} {} agg fit exp 1-4 {} subject {} tune fit exp 0'.format(archname, i, s, j)\n",
    "            net = tuner.train_all(architecture=arch, data=sdata, split=j, startparams=params, freeze=True)\n",
    "            net.save_params(os.path.join(paramsdir, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation\n",
    "\n",
    "doesn't need run more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datafilenames = ['0 (with groups)', '1 (with computer)', '2 (with computer)', '3 (with computer)', '4']\n",
    "datafilenames = [os.path.join(datadir, fname + '.csv') for fname in datafilenames]\n",
    "colnames = ['subject', 'color', 'bp', 'wp', 'zet', 'rt']\n",
    "\n",
    "e0 = pd.read_csv(datafilenames[0], names=colnames+['splitno'])\n",
    "e1 = pd.read_csv(datafilenames[1], names=colnames)\n",
    "e2 = pd.read_csv(datafilenames[2], names=colnames)\n",
    "e3 = pd.read_csv(datafilenames[3], names=colnames+['task', 'taskorder', 'session'])\n",
    "e4 = pd.read_csv(datafilenames[4], names=colnames+['timecondition'])\n",
    "Es = [e1, e2, e3, e4]\n",
    "for i, e in enumerate(Es[1:]):\n",
    "    e['subject'] = e['subject'] + Es[i-1].loc[Es[i-1]['subject']<1000, 'subject'].max()\n",
    "\n",
    "A = pd.concat([e[colnames] for e in [e1, e2, e3, e4]])\n",
    "\n",
    "groups = np.arange(len(A))%5 + 1\n",
    "np.random.seed(100001)\n",
    "np.random.shuffle(groups)\n",
    "A['group'] = groups\n",
    "\n",
    "A.to_csv(os.path.join(datadir, '1-4.csv'), encoding='ASCII', header=False, index=False)\n",
    "A.loc[A['subject']<1000, :].to_csv(\n",
    "    os.path.join(datadir, '1-4 (no computer).csv'), \n",
    "    encoding='ASCII', header=False, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# this is for another training scheme, using preassigned groups in both hvh and other data\n",
    "bulkdata_df = pd.concat([data[0], hvhdata[0]])\n",
    "bulkdata_df.to_csv(os.path.join(datadir, 'bulk.csv'), index=False, header=False)\n",
    "bulkdata = loading.default_loader(os.path.join(datadir, 'bulk.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add groups to fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd_ = pd.read_csv(os.path.join(datadir, 'fake news.csv'), names=['subject', 'color', 'bp', 'wp', 'zet', 'rt'])\n",
    "\n",
    "groups = np.arange(len(fd_)) % 5 + 1\n",
    "np.random.shuffle(groups)\n",
    "fd_['group'] = groups\n",
    "fd_.to_csv(os.path.join(datadir, 'fake news (with groups).csv'), encoding='ASCII', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
