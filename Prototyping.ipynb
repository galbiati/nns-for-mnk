{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imp\n",
    "import numpy as np\n",
    "import theano\n",
    "import lasagne\n",
    "import loading\n",
    "from training import *\n",
    "from network import *\n",
    "from architectures import *\n",
    "\n",
    "L = lasagne.layers\n",
    "nl = lasagne.nonlinearities\n",
    "T = theano.tensor\n",
    "\n",
    "headdir = os.path.expanduser('~/Google Drive/Bas Zahy Gianni - Games')\n",
    "paramsdir = os.path.join(headdir, 'Analysis/0_hvh/Params/nnets/temp')\n",
    "datafile = os.path.join(headdir, 'Data/0_hvh/Clean/_summaries/model_input_with_groups.csv')\n",
    "resultsdir = os.path.join(headdir, 'Analysis/0_hvh/Loglik/nns')\n",
    "data = loading.default_loader(datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CHANGES SINCE PREVIOUS BEST:\n",
    "# - implementation. Now with better abstraction! \n",
    "#     Should have no effect on performance, but dev much easier.\n",
    "# - training algo. Now using Adam instead of SBGD with Nesterov momentum \n",
    "#     mostly just faster convergence...)\n",
    "# - changed activation on conv2d layer to be a pRelu with all units fitted (previously vanilla Relu)\n",
    "# - changed activation on output to be leaky Relu with alpha=.3\n",
    "# - changed initialization on output and conv2d layers to be He with proper func instead of Glorot\n",
    "# - added a \"feature pool\" layer after conv2d. \n",
    "#     This was most impactful; improved performance by ~.05 and reduced overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def default_convnet(input_var=None):\n",
    "    input_shape = (None, 2, 4, 9)\n",
    "    FixLayer = make_FixLayer(input_var)\n",
    "    \n",
    "    input_layer = L.InputLayer(shape=input_shape, input_var=input_var)\n",
    "    network = L.Conv2DLayer(\n",
    "        input_layer, num_filters=32, filter_size=(4,4), pad='full',\n",
    "        nonlinearity=nl.identity\n",
    "    )\n",
    "    \n",
    "    network = L.ParametricRectifierLayer(network, shared_axes='auto') # default: auto\n",
    "    network = L.FeaturePoolLayer(network, pool_function=T.sum, pool_size=2) # default: T.sum, 2\n",
    "    network = L.DropoutLayer(network, p=.75) # default: .75\n",
    "    network = L.DenseLayer(\n",
    "        network, num_units=36, \n",
    "        nonlinearity=nl.very_leaky_rectify, W=lasagne.init.HeUniform(gain='relu')\n",
    "    )\n",
    "    network = FixLayer(network)\n",
    "    network = L.NonlinearityLayer(network, nonlinearity=nl.softmax)\n",
    "    network = FixLayer(network)\n",
    "    network = ReNormLayer(network)\n",
    "    \n",
    "    return network\n",
    "\n",
    "net = Network(default_convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 took 1.390s\n",
      "\ttraining loss:\t\t\t2.9994\n",
      "\tvalidation loss:\t\t2.8461\n",
      "\tvalidation accuracy:\t\t15.53%\n",
      "\ttotal time elapsed:\t\t1.413s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gianni/anaconda/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 took 1.333s\n",
      "\ttraining loss:\t\t\t2.1766\n",
      "\tvalidation loss:\t\t2.1221\n",
      "\tvalidation accuracy:\t\t34.86%\n",
      "\ttotal time elapsed:\t\t71.326s\n",
      "Epoch 100 took 1.335s\n",
      "\ttraining loss:\t\t\t2.0851\n",
      "\tvalidation loss:\t\t2.0693\n",
      "\tvalidation accuracy:\t\t36.33%\n",
      "\ttotal time elapsed:\t\t139.673s\n",
      "Epoch 150 took 1.344s\n",
      "\ttraining loss:\t\t\t2.0626\n",
      "\tvalidation loss:\t\t2.0521\n",
      "\tvalidation accuracy:\t\t37.11%\n",
      "\ttotal time elapsed:\t\t207.949s\n",
      "Epoch 200 took 1.430s\n",
      "\ttraining loss:\t\t\t2.0516\n",
      "\tvalidation loss:\t\t2.0408\n",
      "\tvalidation accuracy:\t\t37.60%\n",
      "\ttotal time elapsed:\t\t279.748s\n",
      "Epoch 250 took 1.365s\n",
      "\ttraining loss:\t\t\t2.0411\n",
      "\tvalidation loss:\t\t2.0461\n",
      "\tvalidation accuracy:\t\t37.21%\n",
      "\ttotal time elapsed:\t\t350.684s\n",
      "Epoch 300 took 1.377s\n",
      "\ttraining loss:\t\t\t2.0343\n",
      "\tvalidation loss:\t\t2.0318\n",
      "\tvalidation accuracy:\t\t37.60%\n",
      "\ttotal time elapsed:\t\t420.298s\n",
      "Epoch 350 took 1.389s\n",
      "\ttraining loss:\t\t\t2.0131\n",
      "\tvalidation loss:\t\t2.0311\n",
      "\tvalidation accuracy:\t\t37.70%\n",
      "\ttotal time elapsed:\t\t490.723s\n",
      "Epoch 400 took 1.444s\n",
      "\ttraining loss:\t\t\t1.9953\n",
      "\tvalidation loss:\t\t2.0219\n",
      "\tvalidation accuracy:\t\t38.57%\n",
      "\ttotal time elapsed:\t\t562.329s\n",
      "Epoch 450 took 1.378s\n",
      "\ttraining loss:\t\t\t1.9981\n",
      "\tvalidation loss:\t\t2.0228\n",
      "\tvalidation accuracy:\t\t37.99%\n",
      "\ttotal time elapsed:\t\t634.259s\n",
      "Abandon ship!\n",
      "TEST PERFORMANCE\n",
      "\tStopped in epoch:\t\t476\n",
      "\tTest loss:\t\t\t2.1524\n",
      "\tTest accuracy:\t\t\t35.25%\n",
      "Epoch 0 took 1.377s\n",
      "\ttraining loss:\t\t\t3.0204\n",
      "\tvalidation loss:\t\t2.8878\n",
      "\tvalidation accuracy:\t\t13.57%\n",
      "\ttotal time elapsed:\t\t1.402s\n",
      "Epoch 50 took 1.297s\n",
      "\ttraining loss:\t\t\t2.1858\n",
      "\tvalidation loss:\t\t2.2661\n",
      "\tvalidation accuracy:\t\t31.93%\n",
      "\ttotal time elapsed:\t\t71.086s\n"
     ]
    }
   ],
   "source": [
    "trainer = DefaultTrainer(stopthresh=100) # default: 125\n",
    "net_list = trainer.train_all(architecture=default_convnet, data=data, seed=985227)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subject prototyping\n",
    "\n",
    "TODO:\n",
    "\n",
    "try saving parameters from above and doing a reload/partial freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Epoch 0 took 0.023s\n",
      "\ttraining loss:\t\t\t6.1382\n",
      "\tvalidation loss:\t\t3.5240\n",
      "\tvalidation accuracy:\t\t6.25%\n",
      "\ttotal time elapsed:\t\t0.024s\n",
      "Epoch 50 took 0.022s\n",
      "\ttraining loss:\t\t\t2.5513\n",
      "\tvalidation loss:\t\t2.5485\n",
      "\tvalidation accuracy:\t\t18.75%\n",
      "\ttotal time elapsed:\t\t1.127s\n",
      "Abandon ship!\n",
      "TEST PERFORMANCE\n",
      "\tStopped in epoch:\t\t74\n",
      "\tTest loss:\t\t\t2.8323\n",
      "\tTest accuracy:\t\t\t6.25\n",
      "Epoch 0 took 0.022s\n",
      "\ttraining loss:\t\t\t6.6821\n",
      "\tvalidation loss:\t\t3.4139\n",
      "\tvalidation accuracy:\t\t6.25%\n",
      "\ttotal time elapsed:\t\t0.022s\n",
      "Epoch 50 took 0.022s\n",
      "\ttraining loss:\t\t\t2.5866\n",
      "\tvalidation loss:\t\t2.7526\n",
      "\tvalidation accuracy:\t\t6.25%\n",
      "\ttotal time elapsed:\t\t1.144s\n",
      "Abandon ship!\n",
      "TEST PERFORMANCE\n",
      "\tStopped in epoch:\t\t90\n",
      "\tTest loss:\t\t\t2.9185\n",
      "\tTest accuracy:\t\t\t0.00\n",
      "Epoch 0 took 0.023s\n",
      "\ttraining loss:\t\t\t6.2076\n",
      "\tvalidation loss:\t\t3.2042\n",
      "\tvalidation accuracy:\t\t12.50%\n",
      "\ttotal time elapsed:\t\t0.023s\n",
      "Abandon ship!\n",
      "TEST PERFORMANCE\n",
      "\tStopped in epoch:\t\t45\n",
      "\tTest loss:\t\t\t2.6970\n",
      "\tTest accuracy:\t\t\t18.75\n",
      "Epoch 0 took 0.024s\n",
      "\ttraining loss:\t\t\t6.1728\n",
      "\tvalidation loss:\t\t3.2733\n",
      "\tvalidation accuracy:\t\t6.25%\n",
      "\ttotal time elapsed:\t\t0.025s\n",
      "Epoch 50 took 0.022s\n",
      "\ttraining loss:\t\t\t2.4819\n",
      "\tvalidation loss:\t\t2.8074\n",
      "\tvalidation accuracy:\t\t6.25%\n",
      "\ttotal time elapsed:\t\t1.170s\n",
      "Abandon ship!\n",
      "TEST PERFORMANCE\n",
      "\tStopped in epoch:\t\t56\n",
      "\tTest loss:\t\t\t2.6833\n",
      "\tTest accuracy:\t\t\t18.75\n",
      "Epoch 0 took 0.022s\n",
      "\ttraining loss:\t\t\t6.2884\n",
      "\tvalidation loss:\t\t3.0362\n",
      "\tvalidation accuracy:\t\t6.25%\n",
      "\ttotal time elapsed:\t\t0.023s\n",
      "Abandon ship!\n",
      "TEST PERFORMANCE\n",
      "\tStopped in epoch:\t\t42\n",
      "\tTest loss:\t\t\t2.6921\n",
      "\tTest accuracy:\t\t\t18.75\n",
      "OVERALL RESULTS\n",
      "\tAverage NLL:\t\t2.765\n",
      "\tCred. Interval:\t\t[2.633, 2.896]\n",
      "\tTotal time:\t\t14.33\n"
     ]
    }
   ],
   "source": [
    "def subject_convnet(input_var=None):\n",
    "    input_shape = (None, 2, 4, 9)\n",
    "    FixLayer = make_FixLayer(input_var)\n",
    "    \n",
    "    network = L.InputLayer(shape=input_shape, input_var=input_var)\n",
    "    network = L.Conv2DLayer(\n",
    "        network, num_filters=32, filter_size=(4,4), pad='full',\n",
    "        nonlinearity=nl.very_leaky_rectify, W=lasagne.init.HeUniform(gain='relu') #GlorotUniform()\n",
    "    )\n",
    "    \n",
    "#     network = L.ParametricRectifierLayer(network, shared_axes='auto')\n",
    "    network = L.DropoutLayer(network, p=.75)\n",
    "\n",
    "    network = L.FeaturePoolLayer(network, pool_function=T.sum, pool_size=8)\n",
    "\n",
    "    network = L.DropoutLayer(network, p=.75)\n",
    "    network = L.DenseLayer(\n",
    "        network, num_units=36, \n",
    "        nonlinearity=nl.very_leaky_rectify, W=lasagne.init.HeUniform(gain='relu')\n",
    "    )\n",
    "    network = L.NonlinearityLayer(network, nonlinearity=nl.softmax)\n",
    "    network = FixLayer(network)\n",
    "    \n",
    "    return network\n",
    "\n",
    "\n",
    "test_sub = 10\n",
    "subject_Xs = data[2]\n",
    "subject_ys = data[3]\n",
    "subject_Ss = data[4]\n",
    "\n",
    "S0 = [np.where(s==test_sub)[0] for s in subject_Ss]\n",
    "print(len(S0[0]))\n",
    "X0 = [subject_Xs[i][s] for i, s in enumerate(S0)]\n",
    "y0 = [subject_ys[i][s] for i, s in enumerate(S0)]\n",
    "\n",
    "sub0_data = (data[0], data[1], X0, y0, S0)\n",
    "sub0_trainer = DefaultTrainer(batchsize=16, stopthresh=20, update_args={'learning_rate':.000001})\n",
    "sub0_net_list = sub0_trainer.train_all(architecture=subject_convnet, data=sub0_data, seed=985227)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoencoder_prototype(input_var=None):\n",
    "    input_shape = (None, 2, 4, 9)\n",
    "    inpuL.InputLayer = L.InputLayer(shape=input_shape, input_var=input_var)\n",
    "    network = L.COnv2DLayer(\n",
    "        input_layer, num_filters=32, filter_size=(4, 4), pad='full',\n",
    "        nonlinearity=nl.identity\n",
    "    )\n",
    "    L.ParametricRectifierLayerrLayeshared_axes=Rectifier(network, shL.FeaturePoolLayerl')\n",
    "    network = L.FeaturePoolLayer(network, pool_functioL.DropoutLayerm, pool_size=2)\n",
    "    network = L.DropoutLayer(network, p=.75)\n",
    "    network = L.DenseLayer(\n",
    "        network, num_units=72,\n",
    "        nonlinearity=nl.very_leaky_rectify, W=lasagne.init.HeUniform(gain='relu')\n",
    "    )\n",
    "    network = L.ReshapeLayer(\n",
    "        network, shape=(-1, 2, 4, 9)\n",
    "    )\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder(Network):\n",
    "    \"\"\"\n",
    "    Overwrites loss functions for training an autoencoder instead\n",
    "    of softmax output classifier\n",
    "    \"\"\"\n",
    "    def objectives(self):\n",
    "        \"\"\"Must define: loss, test_loss, test_acc\"\"\"\n",
    "        self.loss = lasagne.objectives.squared_error(self.prediction, self.target_var)\n",
    "        self.loss = self.loss.mean()\n",
    "        self.test_loss = lasagne.objectives.squared_error(self.test_prediction, self.target_var)\n",
    "        self.test_loss = self.test_loss.mean()\n",
    "        self.test_acc = T.mean(T.abs(self.test_prediction - self.target_var))\n",
    "        return None\n",
    "\n",
    "# class AutoTrainer(DefaultTrainer):\n",
    "#     \"\"\"\n",
    "#     Overwrites training functions for training an autoencoder instead\n",
    "#     of softmax output classifier\n",
    "#     \"\"\"\n",
    "#     pass\n",
    "\n",
    "# Can actually pass data to existing trainer by replacing ys with a copy of Xs!\n",
    "\n",
    "class LadderNet(Network):\n",
    "    \"\"\"\n",
    "    Loads conv layer params from autoencoder save and sets them on current classifier\n",
    "    Needs overwrite of self.build() that loads conv2d params, then sets them untrainable.\n",
    "    \"\"\"\n",
    "    def __init__(self, architecture, paramsfile):\n",
    "        self.paramsfile = paramsfile\n",
    "        super(LadderNet, self).__init__(architecture)\n",
    "    \n",
    "    def build(self):\n",
    "        super(LadderNet, self).build()\n",
    "        \n",
    "        # Finish this soon!\n",
    "        return None\n",
    "    \n",
    "    def load_conv_params(self):\n",
    "        with np.load(paramsfile) as loaded:\n",
    "            L."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import bayes_mvs as bmvs\n",
    "bmvs([n.test_err for n in net_list], alpha=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "D, groups, Xs, ys, Ss = loading.default_loader(datafile)\n",
    "\n",
    "splitsize = len(Xs)\n",
    "r = np.arange(splitsize)\n",
    "r = np.tile(r, [splitsize, 1])\n",
    "r = r + r.T\n",
    "split_indices = r % splitsize\n",
    "\n",
    "split = 0\n",
    "train_i = split_indices[split, :3]\n",
    "val_i = split_indices[split, 3:4]\n",
    "test_i = split_indices[split, 4:]\n",
    "\n",
    "X, y, S = [np.concatenate(np.array(Zs)[train_i]) for Zs in [Xs, ys, Ss]]\n",
    "Xv, yv, Sv = [np.concatenate(np.array(Zs)[val_i]) for Zs in [Xs, ys, Ss]]\n",
    "Xt, yt, St = [np.concatenate(np.array(Zs)[test_i]) for Zs in [Xs, ys, Ss]]\n",
    "X, y = loading.augment((X, y))\n",
    "S = np.concatenate([S, S, S, S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(985227)\n",
    "\n",
    "net = Network(default_convnet)\n",
    "trainer = Trainer()\n",
    "\n",
    "trainer.train(net, training_data=(X, y), validation_data=(Xv, yv))\n",
    "err, acc, bats = trainer.test(net, (Xt, yt))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
