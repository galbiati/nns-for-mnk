{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import imp\n",
    "import numpy as np\n",
    "import theano\n",
    "import lasagne\n",
    "import loading\n",
    "from training import *\n",
    "from network import *\n",
    "from architectures import *\n",
    "\n",
    "L = lasagne.layers\n",
    "nl = lasagne.nonlinearities\n",
    "T = theano.tensor\n",
    "\n",
    "headdir = os.path.expanduser('~/Google Drive/Bas Zahy Gianni - Games')\n",
    "datafile = os.path.join(headdir, 'Data/0_hvh/Clean/_summaries/model_input_with_groups.csv')\n",
    "resultsdir = os.path.join(headdir, 'Analysis/0_hvh/Loglik/nns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def default_convnet(input_var=None):\n",
    "    input_shape = (None, 2, 4, 9)\n",
    "    FixLayer = make_FixLayer(input_var)\n",
    "    \n",
    "    input_layer = L.InputLayer(shape=input_shape, input_var=input_var)\n",
    "    network = L.Conv2DLayer(\n",
    "        input_layer, num_filters=32, filter_size=(4,4), pad='full',\n",
    "        nonlinearity=nl.identity#very_leaky_rectify, W=lasagne.init.HeUniform(gain='relu') #GlorotUniform()\n",
    "    )\n",
    "    \n",
    "    network = L.ParametricRectifierLayer(network, shared_axes='auto')\n",
    "    \n",
    "    network = L.FeaturePoolLayer(network, pool_function=T.sum, pool_size=2)\n",
    "    network = L.DropoutLayer(network, p=.75)\n",
    "    network = L.DenseLayer(\n",
    "        network, num_units=36, \n",
    "        nonlinearity=nl.very_leaky_rectify, W=lasagne.init.HeUniform(gain='relu')\n",
    "    )\n",
    "    network = L.NonlinearityLayer(network, nonlinearity=nl.softmax)\n",
    "    network = FixLayer(network)\n",
    "    \n",
    "    return network\n",
    "\n",
    "net = Network(default_convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 took 1.423s\n",
      "\ttraining loss:\t\t\t2.9994\n",
      "\tvalidation loss:\t\t2.8461\n",
      "\tvalidation accuracy:\t\t15.53%\n",
      "\ttotal time elapsed:\t\t1.448s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gianni/anaconda/lib/python3.5/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 took 1.304s\n",
      "\ttraining loss:\t\t\t2.1766\n",
      "\tvalidation loss:\t\t2.1221\n",
      "\tvalidation accuracy:\t\t34.86%\n",
      "\ttotal time elapsed:\t\t75.348s\n",
      "Epoch 100 took 1.427s\n",
      "\ttraining loss:\t\t\t2.0851\n",
      "\tvalidation loss:\t\t2.0693\n",
      "\tvalidation accuracy:\t\t36.33%\n",
      "\ttotal time elapsed:\t\t144.104s\n"
     ]
    }
   ],
   "source": [
    "data = loading.default_loader(datafile)\n",
    "trainer = DefaultTrainer()\n",
    "net_list = trainer.train_all(architecture=default_convnet, data=data, seed=985227)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoencoder_prototype(input_var=None):\n",
    "    input_shape = (None, 2, 4, 9)\n",
    "    inpuL.InputLayer = L.InputLayer(shape=input_shape, input_var=input_var)\n",
    "    network = L.COnv2DLayer(\n",
    "        input_layer, num_filters=32, filter_size=(4, 4), pad='full',\n",
    "        nonlinearity=nl.identity\n",
    "    )\n",
    "    L.ParametricRectifierLayerrLayeshared_axes=Rectifier(network, shL.FeaturePoolLayerl')\n",
    "    network = L.FeaturePoolLayer(network, pool_functioL.DropoutLayerm, pool_size=2)\n",
    "    network = L.DropoutLayer(network, p=.75)\n",
    "    network = L.DenseLayer(\n",
    "        network, num_units=72,\n",
    "        nonlinearity=nl.very_leaky_rectify, W=lasagne.init.HeUniform(gain='relu')\n",
    "    )\n",
    "    network = L.ReshapeLayer(\n",
    "        network, shape=(-1, 2, 4, 9)\n",
    "    )\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autoencoder(Network):\n",
    "    \"\"\"\n",
    "    Overwrites loss functions for training an autoencoder instead\n",
    "    of softmax output classifier\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class AutoTrainer(DefaultTrainer):\n",
    "    \"\"\"\n",
    "    Overwrites training functions for training an autoencoder instead\n",
    "    of softmax output classifier\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import bayes_mvs as bmvs\n",
    "bmvs([n.test_err for n in net_list], alpha=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "D, groups, Xs, ys, Ss = loading.default_loader(datafile)\n",
    "\n",
    "splitsize = len(Xs)\n",
    "r = np.arange(splitsize)\n",
    "r = np.tile(r, [splitsize, 1])\n",
    "r = r + r.T\n",
    "split_indices = r % splitsize\n",
    "\n",
    "split = 0\n",
    "train_i = split_indices[split, :3]\n",
    "val_i = split_indices[split, 3:4]\n",
    "test_i = split_indices[split, 4:]\n",
    "\n",
    "X, y, S = [np.concatenate(np.array(Zs)[train_i]) for Zs in [Xs, ys, Ss]]\n",
    "Xv, yv, Sv = [np.concatenate(np.array(Zs)[val_i]) for Zs in [Xs, ys, Ss]]\n",
    "Xt, yt, St = [np.concatenate(np.array(Zs)[test_i]) for Zs in [Xs, ys, Ss]]\n",
    "X, y = loading.augment((X, y))\n",
    "S = np.concatenate([S, S, S, S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(985227)\n",
    "\n",
    "net = Network(default_convnet)\n",
    "trainer = Trainer()\n",
    "\n",
    "trainer.train(net, training_data=(X, y), validation_data=(Xv, yv))\n",
    "err, acc, bats = trainer.test(net, (Xt, yt))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
