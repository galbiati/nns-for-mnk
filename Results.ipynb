{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d90a54e3-3a80-4670-b7f9-16344f67f08b"
    }
   },
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "bbbb3ea3-a3ad-467f-bf63-edecc84fae20"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import lasagne\n",
    "import loading\n",
    "from training import *\n",
    "from network import *\n",
    "import architectures as arches\n",
    "from scipy.stats import bayes_mvs, entropy, linregress, spearmanr\n",
    "\n",
    "# aliases\n",
    "L = lasagne.layers\n",
    "nl = lasagne.nonlinearities\n",
    "T = theano.tensor\n",
    "bmvs = bayes_mvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5c91b643-dfe7-4296-bf7f-189ff156605d"
    }
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "a6c5f1f9-5c8c-4fba-9aca-65e87ee14e77"
    }
   },
   "outputs": [],
   "source": [
    "headdir = os.path.expanduser('~/Google Drive/Bas Zahy Gianni - Games')\n",
    "paramsdir_ = os.path.join(headdir, 'Analysis/0_hvh/Params/nnets/')\n",
    "datadir = os.path.join(headdir, 'Data/model input')\n",
    "resultsdir = os.path.join(headdir, 'Analysis/0_hvh/Loglik/nnets')\n",
    "\n",
    "data = loading.default_loader(os.path.join(datadir, '1-4 (no computer).csv'))\n",
    "fake_data = loading.default_loader(os.path.join(datadir, 'fake news (with groups).csv'))\n",
    "hvhdata = loading.default_loader(os.path.join(datadir, '0 (with groups).csv'))\n",
    "df = hvhdata[0]\n",
    "Xs = np.concatenate(hvhdata[2])\n",
    "ys = np.concatenate(hvhdata[3])\n",
    "Ss = np.concatenate(hvhdata[4])\n",
    "\n",
    "defmod = np.loadtxt(os.path.expanduser('~/Downloads/loglik_hvh_final.txt')).reshape([40, 5])\n",
    "\n",
    "with open('arch_specs.yaml') as archfile:\n",
    "    arch_dict = yaml.load(archfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9a3a2e64-2ff9-46e2-bbd8-befcce0fcd2f"
    }
   },
   "source": [
    "## Compile Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unfreeze(net):\n",
    "    # move this function onto Network class!\n",
    "    for layer in L.get_all_layers(net.net):\n",
    "        for param in layer.params:\n",
    "            layer.params[param].add('trainable')\n",
    "    net.params = L.get_all_params(net.net, trainable=True)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def compute_pretrained_results(archname, idx, test_data, fake=False):\n",
    "    Xt, yt = test_data\n",
    "    specs = arch_dict[archname]\n",
    "    af = getattr(arches, arch_dict[archname]['type'])\n",
    "    arch_func = lambda input_var: af(input_var, **specs['kwargs'])\n",
    "    if fake:\n",
    "        fname = '{} {} split fake data.npz'.format('fake_' + archname, idx)\n",
    "        paramsdir = os.path.join(paramsdir_, 'fake_' + archname)\n",
    "    else:\n",
    "        fname = '{} {} split agg fit exp 1-4.npz'.format(archname.replace('_', ' '), idx)\n",
    "        paramsdir = os.path.join(paramsdir_, archname[:-1])\n",
    "\n",
    "    results_df = pd.DataFrame(index=np.arange(Xt.shape[0]), columns=[idx])\n",
    "\n",
    "    net = Network(arch_func)\n",
    "    \n",
    "    net.load_params(os.path.join(paramsdir, fname))\n",
    "\n",
    "    nlls = net.itemized_test_fn(Xt, yt)\n",
    "    predictions = net.output_fn(Xt)\n",
    "    results_df[idx] = nlls\n",
    "    \n",
    "    n_params = L.count_params(net.net)\n",
    "    return results_df, predictions, n_params\n",
    "\n",
    "def compute_tuned_results(archname, idx, test_idx, test_data):\n",
    "    Xt, yt = test_data\n",
    "    group_idx = (test_idx - 1) % 5 # fix eventually to take df/groupidx/selection passed independently?\n",
    "    selection = df.loc[df['group']==(group_idx+1)].index.values\n",
    "    results_df = pd.DataFrame(index=np.arange(Xt.shape[0]), columns=[idx])\n",
    "    predictions_df = pd.DataFrame(index=selection, columns=np.arange(36))\n",
    "    \n",
    "    specs = arch_dict[archname]\n",
    "    af = getattr(arches, arch_dict[archname]['type'])\n",
    "    arch_func = lambda input_var: af(input_var, **specs['kwargs'])\n",
    "    fname = '{} {} agg fit exp 1-4 {} tune fit exp 0.npz'.format(archname.replace('_', ' '), idx, test_idx)\n",
    "    \n",
    "    net = Network(arch_func)\n",
    "    net.load_params(os.path.join(paramsdir_, archname[:-1], fname))\n",
    "    \n",
    "    nlls = net.itemized_test_fn(Xt[selection, :, :, :], yt[selection])\n",
    "    predictions = net.output_fn(Xt[selection, :, :, :])\n",
    "    predictions_df.loc[selection, :] = predictions\n",
    "    results_df.loc[selection, idx] = nlls\n",
    "    return results_df, predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xt, yt, _, _, _ = loading.unpack_data(df)\n",
    "PTR = {}\n",
    "TR = {}\n",
    "param_counts = {}\n",
    "\n",
    "for archname in arch_dict.keys():\n",
    "    arch_dir = archname[:-1]\n",
    "\n",
    "    if arch_dir not in os.listdir(paramsdir_):\n",
    "        print(\"{} not started\".format(archname[:-1]))\n",
    "        continue\n",
    "    \n",
    "    files = os.listdir(os.path.join(paramsdir_, arch_dir))\n",
    "    if not any(archname.replace('_', ' ') in f for f in files):\n",
    "        print(\"{} not started\".format(archname))\n",
    "        continue\n",
    "        \n",
    "    if archname in ['deep_c1']:\n",
    "        print(archname, 'not found')\n",
    "        continue\n",
    "        \n",
    "    print(archname)\n",
    "\n",
    "    pretrain_results = []\n",
    "    pretrain_outputs = []\n",
    "\n",
    "    for idx in range(5):\n",
    "        results_df, predictions_df, n_params = compute_pretrained_results(archname, idx, (Xt, yt))\n",
    "        pretrain_results.append(results_df)\n",
    "        pretrain_outputs.append(predictions_df)\n",
    "\n",
    "    pretrain_results = pd.concat(pretrain_results, axis=1)\n",
    "    PTR[archname] = pretrain_results\n",
    "    param_counts[archname] = n_params\n",
    "    \n",
    "    tune_results = []\n",
    "    tune_predictions = []\n",
    "\n",
    "    for idx in range(5):\n",
    "        for test_idx in range(5):\n",
    "            results_df, predictions_df  = compute_tuned_results(archname, idx, test_idx, (Xt, yt))\n",
    "            tune_results.append(results_df)\n",
    "            tune_predictions.append(predictions_df)\n",
    "\n",
    "    tune_results = pd.concat(tune_results, axis=1, join='inner').stack().unstack()\n",
    "    TR[archname] = trune_results\n",
    "    \n",
    "    pretrain_results.to_csv(os.path.join(resultsdir, 'pretrain {}.csv'.format(archname)))\n",
    "    tune_results.to_csv(os.path.join(resultsdir, 'train {}.csv'.format(archname)))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pc_series = pd.Series(param_counts)\n",
    "pc_series.to_csv(os.path.join(resultsdir, 'params per net.csv'))\n",
    "F = pd.DataFrame(index=np.arange(len(pc_series.index)), columns=['net name'])\n",
    "F['net name'] = pc_series.index\n",
    "F['num params'] = pc_series.values\n",
    "\n",
    "for k, v in PTR.items():\n",
    "    for col in range(5):\n",
    "        new_col_name = 'Pretrained {}'.format(col)\n",
    "        idx = F['net name'] == k\n",
    "        F.loc[idx, new_col_name] = v.pivot_table(index=df['subject'], values=col).mean()\n",
    "        \n",
    "for k, v in TR.items():\n",
    "    for col in range(5):\n",
    "        D = pd.read_csv(os.path.join(resultsdir, 'train {}.csv'.format(k))).drop('Unnamed: 0', axis=1)\n",
    "        new_col_name = 'Tuned {}'.format(col)\n",
    "        idx = F['net name'] == k\n",
    "        F.loc[idx, new_col_name] = D.pivot_table(index=df['subject'], values=str(col)).mean()\n",
    "\n",
    "tuned_cols = ['Tuned {}'.format(i) for i in range(5)]\n",
    "untuned_cols = ['Pretrained {}'.format(i) for i in range(5)]\n",
    "F['tuned mean'] = F[tuned_cols].mean(axis=1)\n",
    "F['untuned mean'] = F[untuned_cols].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "for net_name in F['net name']:\n",
    "    if 'deep' in net_name:\n",
    "        color = 'green'\n",
    "    elif 'regular' in net_name:\n",
    "        color = 'red'\n",
    "    else:\n",
    "        color = 'purple'\n",
    "        \n",
    "    idx = F['net name'] == net_name\n",
    "    x = F.loc[idx, 'num params'].values[0]\n",
    "    y = F.loc[idx, 'tuned mean'].values[0]\n",
    "    axes.plot(x, y, linestyle='none', marker='o', color=color)\n",
    "\n",
    "plt.setp(axes, xlabel='# parameters', ylabel='NLL', xlim=[0, 10000])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F.to_csv(os.path.join(resultsdir, 'num params with nlls.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FD = fake_data[0]\n",
    "HH = hvhdata[0]\n",
    "AD = data[0]\n",
    "\n",
    "FD['position'] = FD['bp'] + FD['wp']\n",
    "HH['position'] = HH['bp'] + FD['wp']\n",
    "AD['position'] = AD['bp'] + AD['wp']\n",
    "\n",
    "def entropy_zets(zets):\n",
    "    z_ = np.histogram(zets, bins=np.arange(37), normed=True)[0]\n",
    "    z_ = z_[z_ > 0]\n",
    "    return -(z_ * np.log(z_)).sum()\n",
    "\n",
    "FDpiv = FD.pivot_table(index='position', values='zet', aggfunc=entropy_zets)\n",
    "HHpiv = HH.pivot_table(index='position', values='zet', aggfunc=entropy_zets)\n",
    "ADpiv = AD.pivot_table(index='position', values='zet', aggfunc=entropy_zets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(FDpiv), len(ADpiv), len(HHpiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDpiv.loc[FDpiv.values > 0].mean(), ADpiv.loc[ADpiv.values > 0].mean(), HHpiv.loc[HHpiv.values > 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDpiv.mean(), ADpiv.mean(), HHpiv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archname = 'h4'\n",
    "Xt, yt, _, _, _ = loading.unpack_data(df)\n",
    "\n",
    "\n",
    "pretrain_results = []\n",
    "pretrain_outputs = []\n",
    "\n",
    "for idx in range(5):\n",
    "    results_df, predictions_df = compute_pretrained_results(archname, idx, (Xt, yt))\n",
    "    pretrain_results.append(results_df)\n",
    "    pretrain_outputs.append(predictions_df)\n",
    "\n",
    "pretrain_results = pd.concat(pretrain_results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_results.to_csv(os.path.join(resultsdir, 'pretrain {}.csv'.format(archname)))\n",
    "\n",
    "for i, o in enumerate(pretrain_outputs):\n",
    "    np.savetxt(os.path.join(resultsdir, 'network_predictions', '{}.csv'.format(i)), o, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_results['mean'] = pretrain_results.mean(axis=1)\n",
    "pretrain_results.pivot_table(index=df['subject'], values='mean').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archname = 'h4'\n",
    "Xt, yt, _, _, _ = loading.unpack_data(fake_data[0])\n",
    "\n",
    "fake_results = []\n",
    "fake_outputs = []\n",
    "\n",
    "specs = arch_dict[archname]\n",
    "af = getattr(arches, arch_dict[archname]['type'])\n",
    "arch_func = lambda input_var: af(input_var, **specs['kwargs'])\n",
    "\n",
    "for idx in range(5):\n",
    "    fname = '{} {} split agg fit exp 1-4.npz'.format(archname, idx)\n",
    "    paramsdir = os.path.join(paramsdir_, archname[:-1])\n",
    "\n",
    "    net = Network(arch_func)\n",
    "    net.load_params(os.path.join(paramsdir, fname))\n",
    "    nlls = net.itemized_test_fn(Xt, yt)\n",
    "    predictions = net.output_fn(Xt)\n",
    "\n",
    "\n",
    "    fake_results.append(nlls)\n",
    "    fake_outputs.append(predictions)\n",
    "\n",
    "fake_results_df = pd.DataFrame(fake_results).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_results_df.pivot_table(index=fake_data[0]['subject']).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archname = 'h4'\n",
    "Xt, yt, _, _, _ = loading.unpack_data(df)\n",
    "\n",
    "pretrain_results = []\n",
    "pretrain_outputs = []\n",
    "\n",
    "for idx in range(5):\n",
    "#     print(idx)\n",
    "    results_df, predictions_df, n_params = compute_pretrained_results(archname, idx, (Xt, yt), fake=True)\n",
    "    pretrain_results.append(results_df)\n",
    "    pretrain_outputs.append(predictions_df)\n",
    "\n",
    "pretrain_results = pd.concat(pretrain_results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_results.pivot_table(index=hvhdata[0]['subject']).mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nets = []\n",
    "train_results = []\n",
    "train_outputs = []\n",
    "\n",
    "for idx in range(5):\n",
    "    for test_idx in range(5):\n",
    "        resdf, outputs, net = load_train_results(archname, archfunc, idx, test_idx)\n",
    "        train_nets.append(net)\n",
    "        train_results.append(resdf)\n",
    "        train_outputs.append(outputs)\n",
    "\n",
    "train_results = pd.concat(train_results, axis=1, join='inner').stack().unstack()\n",
    "train_results.to_csv(os.path.join(resultsdir, 'train {}.csv'.format(archname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    D_ = pd.concat(train_outputs[i:5+i]).sort_index()\n",
    "    D_.to_csv(os.path.join(resultsdir, 'network_predictions', 'trained {}.csv'.format(i)), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results['mean'] = train_results.mean(axis=1)\n",
    "bmvs(train_results.pivot_table(index=df['subject'], values='mean').values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pieces(row):\n",
    "    bp, wp = row[['bp', 'wp']]\n",
    "    n_bp = np.array(list(bp)).astype(int).sum()\n",
    "    n_wp = np.array(list(wp)).astype(int).sum()\n",
    "    \n",
    "    return n_bp + n_wp\n",
    "\n",
    "df['np'] = df.apply(count_pieces, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chancenll = lambda x: -np.log(1/(36-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chancenll'] = chancenll(df['np'].values)\n",
    "df['m'] = -(train_results.mean(axis=1).values - df['chancenll'])\n",
    "np_v_m = df.pivot_table(index='np', values='m')\n",
    "np_v_m.to_csv(os.path.join(resultsdir, 'num_pieces_vs_nll.csv'), header=False)\n",
    "plt.plot(np_v_m)\n",
    "\n",
    "plt.setp(plt.gca(), xlabel='N Pieces', ylabel='NLL relative to chance', ylim=[-.5, 2])\n",
    "\n",
    "sns.despine()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.pivot_table(index='np', values='chancenll'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatterkws = {\n",
    "    'linestyle': 'none', \n",
    "    'marker': 'o', 'markerfacecolor': (.2, .2, .2), 'markeredgecolor': 'black', \n",
    "    'alpha': .3\n",
    "}\n",
    "\n",
    "histkws = {\n",
    "    'edgecolor': 'white'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hicks_entropy(pred):\n",
    "    H = pred * np.log2(1 / (pred + 1))\n",
    "    return H.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, S, G, Np = loading.unpack_data(df)\n",
    "df['mean corrected rt'] = 0\n",
    "for subject in df['subject'].unique():\n",
    "    fil = df['subject'] == subject\n",
    "    df.loc[fil, 'mean corrected rt'] = df.loc[fil, 'rt'] - df.loc[fil, 'rt'].mean()\n",
    "\n",
    "rt = df['mean corrected rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean entropy for each test group\n",
    "E = []\n",
    "for split_idx in range(25):\n",
    "    N = train_nets[split_idx]\n",
    "    locs = np.where(G==(split_idx//5))[0]\n",
    "    L = N.output_fn(X[locs, :, :, :])\n",
    "    E.append(hicks_entropy(L))\n",
    "\n",
    "for g in range(5):\n",
    "    df.loc[df['group']==(g+1), 'entropy'] = np.array(E[g*5:(g+1)*5]).T.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "x = df['entropy']\n",
    "y = np.log(df['rt']/1000)\n",
    "axes.plot(x, y, **scatterkws)\n",
    "lr = linregress(x, y)\n",
    "pval = lr.pvalue if lr.pvalue >= .001 else .001\n",
    "axes.text(.05, .05, r\"r = {:.2f}, p $<$ {:.3f}\".format(lr.rvalue, pval), transform=axes.transAxes, fontsize=14)\n",
    "plt.setp(axes, xlabel=r\"$\\textrm{Entropy}$\", ylabel=r'$\\log{\\textrm{Response time (s)}}$', ylim=[-5, 5])\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hick's law holds (ish)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendata = pd.read_csv(\n",
    "    os.path.join(headdir, 'Data/1_gen/Clean/_summaries/all_evals_model_input.csv'),\n",
    "    names=['subject', 'color', 'bp', 'wp', 'zet', 'rt', 'val']\n",
    ")\n",
    "gendata['group'] = -1\n",
    "\n",
    "X, y, S, G, Np = loading.unpack_data(gendata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = train_nets[0]\n",
    "logistic = lambda x: 1 / (1 + np.exp(-x))\n",
    "zscore = lambda x: (x - x.mean()) / (x.std() / np.sqrt(x.shape[0]))\n",
    "Vr = N.value_fn(X)\n",
    "V = Vr.sum(axis=1)\n",
    "Vl = 7*logistic(zscore(V))\n",
    "\n",
    "V2 = np.zeros_like(V)\n",
    "yz = np.zeros_like(y)\n",
    "for subject in range(S.max()):\n",
    "    V2[S==subject] = zscore(V[S==subject])\n",
    "    yz[S==subject] = zscore(y[S==subject])\n",
    "    \n",
    "V2l = 7*logistic(V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vr = N.value_fn(X) - N.value_fn(X[:, ::-1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(V, **histkws)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(V2, **histkws) #, bins=np.arange(0, 8, .5), **histkws)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(V, gendata['val'], **scatterkws)\n",
    "print(linregress(V2, gendata['val']))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gendata['val'], gendata['zet'], **scatterkws)\n",
    "print(linregress(gendata['zet'], gendata['val']))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(zscore(V), yz, **scatterkws)\n",
    "print(linregress(zscore(V), yz))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gendata['valhat'] = 6*logistic(V2) + 1\n",
    "gendata['valhat'] = gendata['valhat'].map(int)\n",
    "gendata['position'] = gendata['bp'] + gendata['wp']\n",
    "gp = gendata.pivot_table(index='position', columns='zet', values='group', aggfunc=len, fill_value=0)\n",
    "gvp = gendata.pivot_table(index='position', values='valhat')\n",
    "gp['valhat'] = gvp.values\n",
    "gp['valsum'] = gp[list(np.arange(1, 8, 1))].values.argmax(axis=1) + 1\n",
    "gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linregress(gp['valhat'], gp['valsum'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
