{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d90a54e3-3a80-4670-b7f9-16344f67f08b"
    }
   },
   "source": [
    "# Results\n",
    "\n",
    "Testing networks and saving results\n",
    "\n",
    "TODO:\n",
    "- clean up repeated bits into functions\n",
    "- save csv files with results to share/use elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "bbbb3ea3-a3ad-467f-bf63-edecc84fae20"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import yaml\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import lasagne\n",
    "import loading\n",
    "from training import *\n",
    "from network import *\n",
    "from architectures import *\n",
    "from scipy.stats import bayes_mvs, entropy, linregress, spearmanr\n",
    "\n",
    "# aliases\n",
    "L = lasagne.layers\n",
    "nl = lasagne.nonlinearities\n",
    "T = theano.tensor\n",
    "bmvs = bayes_mvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5c91b643-dfe7-4296-bf7f-189ff156605d"
    }
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a6c5f1f9-5c8c-4fba-9aca-65e87ee14e77"
    }
   },
   "outputs": [],
   "source": [
    "headdir = os.path.expanduser('~/Google Drive/Bas Zahy Gianni - Games')\n",
    "paramsdir = os.path.join(headdir, 'Analysis/0_hvh/Params/nnets/temp')\n",
    "datadir = os.path.join(headdir, 'Data/model input')\n",
    "resultsdir = os.path.join(headdir, 'Analysis/0_hvh/Loglik/nnets')\n",
    "\n",
    "data = loading.default_loader(os.path.join(datadir, '1-4 (no computer).csv'))\n",
    "hvhdata = loading.default_loader(os.path.join(datadir, '0 (with groups).csv'))\n",
    "df = hvhdata[0]\n",
    "Xs = np.concatenate(hvhdata[2])\n",
    "ys = np.concatenate(hvhdata[3])\n",
    "Ss = np.concatenate(hvhdata[4])\n",
    "\n",
    "defmod = np.loadtxt(os.path.expanduser('~/Downloads/loglik_hvh_final.txt')).reshape([40, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9a3a2e64-2ff9-46e2-bbd8-befcce0fcd2f"
    }
   },
   "source": [
    "## Compile Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unfreeze(net):\n",
    "    for layer in L.get_all_layers(net.net):\n",
    "        for param in layer.params:\n",
    "            layer.params[param].add('trainable')\n",
    "    net.params = L.get_all_params(net.net, trainable=True)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def load_arch_specs(archname):\n",
    "    with open('arch_specs.yaml') as archfile:\n",
    "        arch = yaml.load(archfile)\n",
    "    return arch[archname]\n",
    "\n",
    "def load_pretrain_results(archname, archfunc, idx, net=None):\n",
    "    specs = load_arch_specs(archname)\n",
    "    arch = lambda input_var: archfunc(input_var, **specs['kwargs'])\n",
    "    fname = '{} {} split agg fit exp 1-4.npz'.format(archname, idx)\n",
    "    resdf = pd.DataFrame(index=np.arange(Xt.shape[0]), columns=[idx])\n",
    "\n",
    "    if net is None:\n",
    "        net = Network(arch)\n",
    "    \n",
    "    net.load_params(os.path.join(paramsdir, fname))\n",
    "    res = net.itemized_test_fn(Xt, yt)\n",
    "    resdf[idx] = res\n",
    "    return resdf, net\n",
    "\n",
    "def load_train_results(archname, archfunc, idx, test_idx, net=None):\n",
    "    specs = load_arch_specs(archname)\n",
    "    arch = lambda input_var: archfunc(input_var, **specs['kwargs'])\n",
    "    fname = '{} {} agg fit exp 1-4 {} tune fit exp 0.npz'.format(archname, idx, test_idx)\n",
    "    resdf = pd.DataFrame(index=np.arange(Xt.shape[0]), columns=[idx])\n",
    "    \n",
    "    if net is None:\n",
    "        net = Network(arch)\n",
    "    \n",
    "    net.load_params(os.path.join(paramsdir, fname))\n",
    "    \n",
    "    group_idx = (test_idx - 1) % 5\n",
    "    selection = df.loc[df['group']==(group_idx+1)].index.values\n",
    "    res = net.itemized_test_fn(Xt[selection, :, :, :], yt[selection])\n",
    "    resdf.loc[selection, idx] = res\n",
    "    return resdf, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "archname = 'h4'\n",
    "archfunc = multiconvX_ws\n",
    "Xt, yt, _, _, _ = loading.unpack_data(df)\n",
    "\n",
    "pretrain_nets = []\n",
    "pretrain_results = []\n",
    "# net = Network()\n",
    "\n",
    "for idx in range(5):\n",
    "    resdf, net = load_pretrain_results(archname, archfunc, idx)\n",
    "    pretrain_nets.append(net)\n",
    "    pretrain_results.append(resdf)\n",
    "\n",
    "pretrain_results = pd.concat(pretrain_results, axis=1)\n",
    "pretrain_results.to_csv(os.path.join(resultsdir, 'pretrain {}.csv'.format(archname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.982299856690378"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrain_results['mean'] = pretrain_results.mean(axis=1)\n",
    "pretrain_results.pivot_table(index=df['subject'], values='mean').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n"
     ]
    }
   ],
   "source": [
    "train_nets = []\n",
    "train_results = []\n",
    "for idx in range(5):\n",
    "    for test_idx in range(5):\n",
    "        print(idx, test_idx)\n",
    "        resdf, net = load_train_results(archname, archfunc, idx, test_idx)\n",
    "        train_nets.append(net)\n",
    "        train_results.append(resdf)\n",
    "\n",
    "train_results = pd.concat(train_results, axis=1, join='inner').stack().unstack()\n",
    "train_results.to_csv(os.path.join(resultsdir, 'train {}.csv'.format(archname)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Mean(statistic=1.9549269570194059, minmax=(1.8640069212399626, 2.045846992798849)),\n",
       " Variance(statistic=0.12277406515959045, minmax=(0.083240882724647969, 0.17678814527682843)),\n",
       " Std_dev(statistic=0.34803206050705632, minmax=(0.28851496100661395, 0.42046182380428837)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results['mean'] = train_results.mean(axis=1)\n",
    "bmvs(train_results.pivot_table(index=df['subject'], values='mean').values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Response Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk')\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scatterkws = {\n",
    "    'linestyle': 'none', \n",
    "    'marker': 'o', 'markerfacecolor': (.2, .2, .2), 'markeredgecolor': 'black', \n",
    "    'alpha': .3\n",
    "}\n",
    "\n",
    "histkws = {\n",
    "    'edgecolor': 'white'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hicks_entropy(pred):\n",
    "    H = pred * np.log2(1 / (pred + 1))\n",
    "    return H.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, S, G, Np = loading.unpack_data(df)\n",
    "df['mean corrected rt'] = 0\n",
    "for subject in df['subject'].unique():\n",
    "    fil = df['subject'] == subject\n",
    "    df.loc[fil, 'mean corrected rt'] = df.loc[fil, 'rt'] - df.loc[fil, 'rt'].mean()\n",
    "\n",
    "rt = df['mean corrected rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute mean entropy for each test group\n",
    "E = []\n",
    "for split_idx in range(25):\n",
    "    N = train_nets[split_idx]\n",
    "    locs = np.where(G==(split_idx//5))[0]\n",
    "    L = N.output_fn(X[locs, :, :, :])\n",
    "    E.append(hicks_entropy(L))\n",
    "\n",
    "for g in range(5):\n",
    "    df.loc[df['group']==(g+1), 'entropy'] = np.array(E[g*5:(g+1)*5]).T.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "x = df['entropy']\n",
    "y = np.log(df['rt']/1000)\n",
    "axes.plot(x, y, **scatterkws)\n",
    "lr = linregress(x, y)\n",
    "pval = lr.pvalue if lr.pvalue >= .001 else .001\n",
    "axes.text(.05, .05, r\"r = {:.2f}, p $<$ {:.3f}\".format(lr.rvalue, pval), transform=axes.transAxes, fontsize=14)\n",
    "plt.setp(axes, xlabel=r\"$\\textrm{Entropy}$\", ylabel=r'$\\log{\\textrm{Response time (s)}}$', ylim=[-5, 5])\n",
    "\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hick's law holds (ish)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gendata = pd.read_csv(\n",
    "    os.path.join(headdir, 'Data/1_gen/Clean/_summaries/all_evals_model_input.csv'),\n",
    "    names=['subject', 'color', 'bp', 'wp', 'zet', 'rt', 'val']\n",
    ")\n",
    "gendata['group'] = -1\n",
    "\n",
    "X, y, S, G, Np = loading.unpack_data(gendata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = train_nets[0]\n",
    "logistic = lambda x: 1 / (1 + np.exp(-x))\n",
    "zscore = lambda x: (x - x.mean()) / (x.std() / np.sqrt(x.shape[0]))\n",
    "Vr = N.value_fn(X)\n",
    "V = Vr.sum(axis=1)\n",
    "Vl = 7*logistic(zscore(V))\n",
    "\n",
    "V2 = np.zeros_like(V)\n",
    "yz = np.zeros_like(y)\n",
    "for subject in range(S.max()):\n",
    "    V2[S==subject] = zscore(V[S==subject])\n",
    "    yz[S==subject] = zscore(y[S==subject])\n",
    "    \n",
    "V2l = 7*logistic(V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vr = N.value_fn(X) - N.value_fn(X[:, ::-1, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(V, **histkws)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(V2, **histkws) #, bins=np.arange(0, 8, .5), **histkws)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(V, gendata['val'], **scatterkws)\n",
    "print(linregress(V2, gendata['val']))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(gendata['val'], gendata['zet'], **scatterkws)\n",
    "print(linregress(gendata['zet'], gendata['val']))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(zscore(V), yz, **scatterkws)\n",
    "print(linregress(zscore(V), yz))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gendata['valhat'] = 6*logistic(V2) + 1\n",
    "gendata['valhat'] = gendata['valhat'].map(int)\n",
    "gendata['position'] = gendata['bp'] + gendata['wp']\n",
    "gp = gendata.pivot_table(index='position', columns='zet', values='group', aggfunc=len, fill_value=0)\n",
    "gvp = gendata.pivot_table(index='position', values='valhat')\n",
    "gp['valhat'] = gvp.values\n",
    "gp['valsum'] = gp[list(np.arange(1, 8, 1))].values.argmax(axis=1) + 1\n",
    "gp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linregress(gp['valhat'], gp['valsum'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
