{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d90a54e3-3a80-4670-b7f9-16344f67f08b"
    }
   },
   "source": [
    "# Results\n",
    "\n",
    "Testing networks and saving results\n",
    "\n",
    "TODO:\n",
    "- clean up repeated bits into functions\n",
    "- save csv files with results to share/use elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "bbbb3ea3-a3ad-467f-bf63-edecc84fae20"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import theano\n",
    "import lasagne\n",
    "import loading\n",
    "from training import *\n",
    "from network import *\n",
    "from architectures import *\n",
    "from scipy.stats import bayes_mvs, entropy, linregress, spearmanr\n",
    "\n",
    "# aliases\n",
    "L = lasagne.layers\n",
    "nl = lasagne.nonlinearities\n",
    "T = theano.tensor\n",
    "bmvs = bayes_mvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5c91b643-dfe7-4296-bf7f-189ff156605d"
    }
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a6c5f1f9-5c8c-4fba-9aca-65e87ee14e77"
    }
   },
   "outputs": [],
   "source": [
    "headdir = os.path.expanduser('~/Google Drive/Bas Zahy Gianni - Games')\n",
    "paramsdir = os.path.join(headdir, 'Analysis/0_hvh/Params/nnets/temp')\n",
    "datadir = os.path.join(headdir, 'Data/model input')\n",
    "resultsdir = os.path.join(headdir, 'Analysis/0_hvh/Loglik/nnets')\n",
    "\n",
    "data = loading.default_loader(os.path.join(datadir, '1-4 (no computer).csv'))\n",
    "hvhdata = loading.default_loader(os.path.join(datadir, '0 (with groups).csv'))\n",
    "df = hvhdata[0]\n",
    "Xs = np.concatenate(hvhdata[2])\n",
    "ys = np.concatenate(hvhdata[3])\n",
    "Ss = np.concatenate(hvhdata[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9a3a2e64-2ff9-46e2-bbd8-befcce0fcd2f"
    }
   },
   "source": [
    "## Compile Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c971ad68-0a00-4398-9d89-5f28953b5f40"
    }
   },
   "outputs": [],
   "source": [
    "num_filters = [4, 8, 16, 32, 64, 128]\n",
    "archnames = [\"arch{}\".format(n) for n in num_filters]\n",
    "columns = pd.MultiIndex.from_product([archnames, np.arange(5).astype(str)])\n",
    "tune_tidy = pd.DataFrame(index=df.index, columns=columns)\n",
    "tune_tidy['subject'] = df['subject']\n",
    "tune_tidy['group'] = df['group'] - 1\n",
    "\n",
    "pretrain_tidy = pd.DataFrame(index=df.index, columns=columns)\n",
    "pretrain_tidy['subject'] = df['subject']\n",
    "pretrain_tidy['group'] = df['group'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "89a6f233-3de6-4174-894c-84b402d7643b"
    }
   },
   "outputs": [],
   "source": [
    "for prefit_idx in range(5):\n",
    "    for test_split in range(5):\n",
    "        # create network container with nfil filters architecture\n",
    "        fname = 'multiconvX_lrg {} agg fit exp 1-4 {} tune fit exp 0.npz'.format(prefit_idx, test_split)\n",
    "\n",
    "        arch = multiconvX\n",
    "        net = Network(arch)\n",
    "        net.load_params(os.path.join(paramsdir, fname))\n",
    "\n",
    "        group_idx = (test_split-1)%5 # fuck this up if you want to see overfitting\n",
    "        test_data = df.loc[df['group']==(group_idx+1)]\n",
    "        Xt, yt, St, Gt, Npt = loading.unpack_data(test_data)\n",
    "        res = net.itemized_test_fn(Xt, yt)\n",
    "        l1 = 'multiconvX'\n",
    "        l2 = str(prefit_idx)\n",
    "        tune_tidy.loc[tune_tidy['group']==group_idx, (l1, l2)] = res\n",
    "\n",
    "    fname = 'multiconvX_lrg {} split agg fit exp 1-4.npz'.format(prefit_idx)\n",
    "\n",
    "    arch = multiconvX\n",
    "    net = Network(arch)\n",
    "    net.load_params(os.path.join(paramsdir, fname))\n",
    "    Xt, yt, St, Gt, Npt = loading.unpack_data(df)\n",
    "    res = net.itemized_test_fn(Xt, yt)\n",
    "    l1 = 'multiconvX'\n",
    "    l2 = str(prefit_idx)\n",
    "    pretrain_tidy[(l1, l2)] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "bd43c2f3-0aae-458d-ba38-85570cb0b653"
    }
   },
   "outputs": [],
   "source": [
    "np.array([i.size for i in L.get_all_param_values(net.net)]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "794c6adb-7357-4948-af68-6377fccbfd85"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pt = tune_tidy[['subject', 'group']].copy()\n",
    "pt.columns = pt.columns.get_level_values(0)\n",
    "pt['multiconvX'] = tune_tidy['multiconvX'].mean(axis=1)\n",
    "ptpiv = pt.pivot_table(index='subject', values='multiconvX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bmvs(ptpiv.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(ptpiv.values, bins=np.arange(1.2, 2.8, .1))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c4bd7cf7-0d3d-4a34-b9bc-d8f32d3e7ebf"
    }
   },
   "outputs": [],
   "source": [
    "for nfil in num_filters:\n",
    "    for prefit_idx in range(5):\n",
    "        for test_split in range(5):\n",
    "            # create network container with nfil filters architecture\n",
    "            if nfil == 32:\n",
    "                fname = '{} agg fit exp 1-4 {} tune fit exp 0.npz'.format(prefit_idx, test_split)\n",
    "            else:\n",
    "                fname = 'arch{} {} agg fit exp 1-4 {} tune fit exp 0.npz'.format(nfil, prefit_idx, test_split)\n",
    "            \n",
    "            arch = lambda input_var: archX(input_var, num_filters=nfil)\n",
    "            net = Network(arch)\n",
    "            net.load_params(os.path.join(paramsdir, fname))\n",
    "            \n",
    "            group_idx = (test_split-1)%5 # fuck this up if you want to see overfitting\n",
    "            test_data = df.loc[df['group']==(group_idx+1)]\n",
    "            Xt, yt, St, Gt, Npt = loading.unpack_data(test_data)\n",
    "            res = net.itemized_test_fn(Xt, yt)\n",
    "            l1 = 'arch{}'.format(nfil)\n",
    "            l2 = str(prefit_idx)\n",
    "            tune_tidy.loc[tune_tidy['group']==group_idx, (l1, l2)] = res\n",
    "\n",
    "        if nfil == 32:\n",
    "            fname = '{} split agg fit exp 1-4.npz'.format(prefit_idx)\n",
    "        else:\n",
    "            fname = 'arch{} {} split agg fit exp 1-4.npz'.format(nfil, prefit_idx)\n",
    "            \n",
    "        arch = lambda input_var: archX(input_var, num_filters=nfil)\n",
    "        net = Network(arch)\n",
    "        net.load_params(os.path.join(paramsdir, fname))\n",
    "        Xt, yt, St, Gt, Npt = loading.unpack_data(df)\n",
    "        res = net.itemized_test_fn(Xt, yt)\n",
    "        l1 = 'arch{}'.format(nfil)\n",
    "        l2 = str(prefit_idx)\n",
    "        pretrain_tidy[(l1, l2)] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "433a94e9-2ec5-4884-962e-4e72fb4167a1"
    }
   },
   "outputs": [],
   "source": [
    "def pivtidy(tidydf):\n",
    "    t = tidydf[archnames].astype(float)\n",
    "    t = t.mean(axis=1, level=0)\n",
    "    t['subject'] = tidydf['subject']\n",
    "    t['group'] = tidydf['group']\n",
    "    tpiv = t.pivot_table(index='subject', values=archnames)\n",
    "    return tpiv\n",
    "\n",
    "pretrain_piv = pivtidy(pretrain_tidy)\n",
    "tune_piv = pivtidy(tune_tidy)\n",
    "\n",
    "print('pretrain agg\\n')\n",
    "for arc in archnames:\n",
    "    print(arc, \"\\n\", bmvs(pretrain_tidy[arc].values), \"\\n\")\n",
    "\n",
    "print('\\npretrain sub\\n')\n",
    "for arc in archnames:\n",
    "    print(arc, \"\\n\", bmvs(pretrain_piv[arc].values), \"\\n\")\n",
    "\n",
    "print('\\ntune agg\\n')\n",
    "for arc in archnames:\n",
    "    print(arc, \"\\n\", bmvs(tune_tidy[arc].values), \"\\n\")\n",
    "\n",
    "print('\\ntune sub\\n')\n",
    "for arc in archnames:\n",
    "    print(arc, \"\\n\", bmvs(tune_piv[arc].values), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
